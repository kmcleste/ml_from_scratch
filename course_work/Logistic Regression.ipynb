{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "### Kyle McLester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy as copy\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "T = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now partition the data \n",
    "\n",
    "\"\"\" partitioning data\n",
    "\n",
    "    parameters\n",
    "    -----------\n",
    "    X        numpy array\n",
    "             input data to partition\n",
    "    T        numpy array\n",
    "             target labels to partition\n",
    "    raito    list\n",
    "             list of ratios for partitions (should be summed to 1) \n",
    "             the number of return pairs are different\n",
    "    return\n",
    "    -------\n",
    "    \n",
    "    Xs       list of numpy arrays\n",
    "    \n",
    "    Ts       list of numpy arrays\n",
    "\"\"\"\n",
    "def partition(X, T, ratio=[0.8, 0.2]): \n",
    "    \n",
    "    # Checks to make sure ratio sums to 1\n",
    "    assert(np.sum(ratio) == 1)\n",
    "    \n",
    "    # Store the number of data samples \n",
    "    N = X.shape[0]\n",
    "\n",
    "    # change the 1d array to 2d if need\n",
    "    if len(T.shape) == 1:\n",
    "        T = T.reshape((N,1))\n",
    "    \n",
    "    # Shuffle the data indices \n",
    "    idxs = np.random.permutation(N)\n",
    "        \n",
    "    Xs = []\n",
    "    Ts = []\n",
    "    i = 0  # first index to zero\n",
    "    for k, r in enumerate(ratio):\n",
    "         # Number of rows that corresponds to kth element in ratios\n",
    "        nrows = int(round(N * r)) \n",
    "        \n",
    "        # print (i, nrows)\n",
    "        # If we are on the last ratio simply use the remaining data samples\n",
    "        if k == len(ratio)-1:\n",
    "            Xs.append(X[idxs[i:], :])\n",
    "            Ts.append(T[idxs[i:], :])\n",
    "        else:\n",
    "            Xs.append(X[idxs[i:i+nrows], :])\n",
    "            Ts.append(T[idxs[i:i+nrows], :])\n",
    "        \n",
    "        i += nrows\n",
    "    \n",
    "    return Xs, Ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_data():\n",
    "    \"\"\"Partition data into train and test splits.\"\"\"\n",
    "    global Xtrain, Xtest, Ttrain, Ttest\n",
    "    data, targets = partition(copy(X), copy(T))\n",
    "    # Fill in the right had side of the assignments below\n",
    "    Xtrain, Xtest = data\n",
    "    # Fill in the right had side of the assignments below\n",
    "    Ttrain, Ttest = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: (120, 4)\n",
      "Train target shape: (120, 1)\n",
      "Test data shape: (30, 4)\n",
      "Test target shape: (30, 1)\n"
     ]
    }
   ],
   "source": [
    "partition_data()\n",
    "print(\"Train data shape: {}\".format(Xtrain.shape))\n",
    "print(\"Train target shape: {}\".format(Ttrain.shape))\n",
    "print(\"Test data shape: {}\".format(Xtest.shape))\n",
    "print(\"Test target shape: {}\".format(Ttest.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2],\n",
       "       [1],\n",
       "       [2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ttrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ttrain == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [ True, False, False],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False,  True, False],\n",
       "       [ True, False, False],\n",
       "       [ True, False, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True],\n",
       "       [False,  True, False],\n",
       "       [False, False,  True]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ttrain == np.unique(Ttrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [1, 0, 0],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 1, 0],\n",
       "       [1, 0, 0],\n",
       "       [1, 0, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1\n",
    "\n",
    "(Ttrain == np.unique(Ttrain)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_indicators():\n",
    "    global Titrain, Titest\n",
    "    Titrain = (Ttrain == np.unique(Ttrain)).astype(int) \n",
    "    Titest = (Ttest == np.unique(Ttest)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train indicator shape: (120, 3)\n",
      "Test indicator shape: (30, 3)\n"
     ]
    }
   ],
   "source": [
    "convert_to_indicators()\n",
    "print(\"Train indicator shape: {}\".format(Titrain.shape))\n",
    "print(\"Test indicator shape: {}\".format(Titest.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (np.argmax(Titrain, axis=1) == Ttrain.flatten()).all()\n",
    "assert (np.argmax(Titest, axis=1) == Ttest.flatten()).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    if not isinstance(z, np.ndarray):\n",
    "        z = np.asarray(z)\n",
    "        \n",
    "    numerator = np.exp(z)\n",
    "\n",
    "    if len(z.shape) == 2:\n",
    "        denominator = np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    else:\n",
    "        denominator = np.sum(np.exp(z))\n",
    "\n",
    "    return numerator / denominator\n",
    "\n",
    "# Wrapper for softmax\n",
    "def g(X, w):\n",
    "\n",
    "    return softmax(X @ w) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.92622126e-174 1.40148307e-091 1.00000000e+000]\n",
      " [1.00000000e+000 3.06830329e-092 0.00000000e+000]\n",
      " [1.16851351e-031 1.00000000e+000 2.51252647e-076]\n",
      " [1.00000000e+000 3.37920155e-092 0.00000000e+000]\n",
      " [1.00123724e-084 5.62032726e-011 1.00000000e+000]\n",
      " [1.00000000e+000 8.78854363e-091 0.00000000e+000]\n",
      " [1.78252759e-102 1.31620337e-026 1.00000000e+000]\n",
      " [9.32477078e-125 1.03481091e-045 1.00000000e+000]\n",
      " [9.09123167e-045 1.00000000e+000 1.27879136e-060]\n",
      " [3.14485112e-033 1.00000000e+000 2.80834611e-075]\n",
      " [3.33817170e-148 1.11240877e-070 1.00000000e+000]\n",
      " [1.00000000e+000 1.27254716e-083 0.00000000e+000]\n",
      " [1.00000000e+000 5.36065203e-077 0.00000000e+000]\n",
      " [6.67150855e-180 1.18028809e-068 1.00000000e+000]\n",
      " [1.00000000e+000 1.74275856e-066 0.00000000e+000]\n",
      " [1.95278238e-158 6.98510850e-094 1.00000000e+000]\n",
      " [2.54317451e-118 1.54484160e-054 1.00000000e+000]\n",
      " [1.00000000e+000 2.39918273e-077 0.00000000e+000]\n",
      " [9.11152400e-161 1.93173945e-073 1.00000000e+000]\n",
      " [1.17901804e-040 1.00000000e+000 1.52888319e-076]\n",
      " [5.15506501e-035 1.00000000e+000 5.32069351e-072]\n",
      " [4.31890881e-054 1.00000000e+000 1.14322880e-035]\n",
      " [3.70612946e-166 5.07650954e-071 1.00000000e+000]\n",
      " [1.00000000e+000 1.23316433e-118 0.00000000e+000]\n",
      " [9.77801659e-046 9.99999944e-001 5.59515093e-008]\n",
      " [8.24959356e-049 5.14457512e-003 9.94855425e-001]\n",
      " [4.56218192e-028 1.00000000e+000 1.31145394e-075]\n",
      " [1.54784907e-047 1.00000000e+000 1.65659853e-034]\n",
      " [1.00000000e+000 1.00729928e-082 0.00000000e+000]\n",
      " [1.19040294e-134 3.91759880e-062 1.00000000e+000]\n",
      " [1.30149343e-129 5.08319208e-063 1.00000000e+000]\n",
      " [2.24283320e-137 1.83072652e-042 1.00000000e+000]\n",
      " [8.47845540e-025 1.00000000e+000 1.32265730e-107]\n",
      " [3.82860008e-031 1.00000000e+000 2.10055805e-052]\n",
      " [2.16337174e-041 1.00000000e+000 1.05867448e-075]\n",
      " [6.43021109e-043 1.00000000e+000 8.09704369e-061]\n",
      " [1.00000000e+000 5.83400896e-093 0.00000000e+000]\n",
      " [3.26839623e-073 1.21136126e-019 1.00000000e+000]\n",
      " [1.00000000e+000 5.65540972e-060 0.00000000e+000]\n",
      " [2.60281418e-044 1.00000000e+000 2.60942477e-062]\n",
      " [5.84755566e-107 8.13812004e-018 1.00000000e+000]\n",
      " [3.33817170e-148 1.11240877e-070 1.00000000e+000]\n",
      " [6.97484611e-122 1.98252469e-046 1.00000000e+000]\n",
      " [6.95116834e-093 1.27496877e-024 1.00000000e+000]\n",
      " [6.10528990e-044 1.00000000e+000 1.21534347e-073]\n",
      " [1.00000000e+000 6.08718898e-067 0.00000000e+000]\n",
      " [1.00000000e+000 1.28609325e-093 0.00000000e+000]\n",
      " [1.00000000e+000 3.01030071e-110 0.00000000e+000]\n",
      " [1.00000000e+000 3.27176235e-074 0.00000000e+000]\n",
      " [2.47919991e-038 1.00000000e+000 2.63320363e-031]\n",
      " [1.17927465e-038 1.00000000e+000 5.43742918e-046]\n",
      " [8.56437128e-166 2.25432561e-084 1.00000000e+000]\n",
      " [1.00000000e+000 1.73378775e-082 0.00000000e+000]\n",
      " [1.00000000e+000 4.98040782e-070 0.00000000e+000]\n",
      " [1.66526415e-055 1.00000000e+000 2.10150830e-026]\n",
      " [1.00000000e+000 2.78290305e-076 0.00000000e+000]\n",
      " [1.00000000e+000 2.91326067e-093 0.00000000e+000]\n",
      " [1.00000000e+000 1.43931082e-094 0.00000000e+000]\n",
      " [1.00000000e+000 5.82690267e-108 0.00000000e+000]\n",
      " [1.00000000e+000 1.55250500e-084 0.00000000e+000]\n",
      " [1.17801165e-115 2.74707688e-037 1.00000000e+000]\n",
      " [4.66986806e-034 1.00000000e+000 1.41848648e-079]\n",
      " [3.77106106e-048 1.00000000e+000 5.27559552e-023]\n",
      " [1.00000000e+000 1.33904893e-084 0.00000000e+000]\n",
      " [1.00000000e+000 1.05592812e-096 0.00000000e+000]\n",
      " [9.87126975e-087 7.18114159e-009 9.99999993e-001]\n",
      " [2.83807474e-045 1.00000000e+000 3.12798812e-050]\n",
      " [1.00000000e+000 2.01964759e-067 0.00000000e+000]\n",
      " [5.75747389e-159 2.54494533e-056 1.00000000e+000]\n",
      " [1.00000000e+000 1.38133643e-117 0.00000000e+000]\n",
      " [1.00000000e+000 1.01848652e-091 0.00000000e+000]\n",
      " [8.46566266e-033 1.00000000e+000 1.11637453e-043]\n",
      " [8.72365337e-129 7.13836134e-068 1.00000000e+000]\n",
      " [1.00000000e+000 3.97643737e-088 0.00000000e+000]\n",
      " [3.25356849e-035 1.00000000e+000 5.40008714e-058]\n",
      " [1.00000000e+000 1.13793222e-088 0.00000000e+000]\n",
      " [1.00000000e+000 2.36256200e-093 0.00000000e+000]\n",
      " [3.30748164e-177 2.19402556e-106 1.00000000e+000]\n",
      " [2.65467172e-062 2.61389538e-016 1.00000000e+000]\n",
      " [2.77642779e-036 1.00000000e+000 1.75564210e-027]\n",
      " [1.53476879e-187 6.56770026e-099 1.00000000e+000]\n",
      " [5.38889071e-011 1.00000000e+000 1.22103878e-102]\n",
      " [9.17790935e-188 7.99965158e-078 1.00000000e+000]\n",
      " [1.00000000e+000 1.65965152e-123 0.00000000e+000]\n",
      " [2.02061843e-106 3.19369259e-040 1.00000000e+000]\n",
      " [2.12732426e-054 1.00000000e+000 1.51061745e-020]\n",
      " [4.22309055e-079 5.27074096e-022 1.00000000e+000]\n",
      " [1.58740963e-111 8.35353698e-046 1.00000000e+000]\n",
      " [2.67689368e-079 5.47404381e-025 1.00000000e+000]\n",
      " [1.88578929e-051 1.00000000e+000 6.55366209e-050]\n",
      " [1.00000000e+000 1.59335187e-078 0.00000000e+000]\n",
      " [8.48669834e-136 7.40268735e-070 1.00000000e+000]\n",
      " [1.00000000e+000 2.62295395e-066 0.00000000e+000]\n",
      " [5.13789955e-047 1.00000000e+000 4.05514852e-033]\n",
      " [6.53897538e-089 8.12532659e-034 1.00000000e+000]\n",
      " [1.43968081e-158 1.84645313e-086 1.00000000e+000]\n",
      " [2.77882554e-164 6.13304636e-094 1.00000000e+000]\n",
      " [3.85387244e-056 1.00000000e+000 1.83247852e-021]\n",
      " [1.09762758e-027 1.00000000e+000 2.60209307e-035]\n",
      " [2.05093934e-127 8.32048153e-048 1.00000000e+000]\n",
      " [1.30211150e-040 1.00000000e+000 1.04616061e-062]\n",
      " [4.81514577e-068 1.00000000e+000 4.90842184e-036]\n",
      " [3.27124285e-160 1.79408831e-069 1.00000000e+000]\n",
      " [1.00000000e+000 3.57691887e-063 0.00000000e+000]\n",
      " [1.96154373e-038 1.00000000e+000 9.39250501e-071]\n",
      " [2.89556706e-179 1.43727127e-089 1.00000000e+000]\n",
      " [1.04978886e-286 2.84005636e-144 1.00000000e+000]\n",
      " [2.69138335e-061 1.00000000e+000 1.14895212e-043]\n",
      " [1.00000000e+000 7.87203363e-080 0.00000000e+000]\n",
      " [9.33289222e-212 1.53260817e-095 1.00000000e+000]\n",
      " [1.70377880e-131 2.94273504e-055 1.00000000e+000]\n",
      " [2.96906529e-075 9.99649152e-001 3.50847908e-004]\n",
      " [1.25651388e-034 1.00000000e+000 3.09103183e-054]\n",
      " [1.00000000e+000 1.46394172e-073 0.00000000e+000]\n",
      " [1.00000000e+000 4.55343748e-082 0.00000000e+000]\n",
      " [3.01761311e-107 2.63274451e-039 1.00000000e+000]\n",
      " [7.93991637e-040 1.00000000e+000 3.02691157e-072]\n",
      " [4.41129412e-218 2.08149333e-134 1.00000000e+000]\n",
      " [3.27355089e-061 1.00000000e+000 2.58240263e-033]\n",
      " [2.61644015e-226 4.69949532e-098 1.00000000e+000]]\n",
      "[[1.00000000e+000 2.29508834e-063 0.00000000e+000]\n",
      " [1.00000000e+000 3.99154356e-075 0.00000000e+000]\n",
      " [8.42025318e-051 1.00000000e+000 2.16025525e-060]\n",
      " [1.00000000e+000 9.16157683e-067 0.00000000e+000]\n",
      " [3.62664148e-154 1.96745193e-066 1.00000000e+000]\n",
      " [3.08962843e-048 1.00000000e+000 1.20415017e-032]\n",
      " [1.00000000e+000 1.74196344e-067 0.00000000e+000]\n",
      " [1.00000000e+000 9.12690441e-080 0.00000000e+000]\n",
      " [1.00000000e+000 1.42718977e-067 0.00000000e+000]\n",
      " [6.77403824e-162 5.83982268e-087 1.00000000e+000]\n",
      " [4.40092942e-168 1.25804778e-061 1.00000000e+000]\n",
      " [1.57887647e-015 1.00000000e+000 5.25393865e-084]\n",
      " [1.00000000e+000 3.22035277e-091 0.00000000e+000]\n",
      " [1.01713454e-038 1.00000000e+000 4.53261895e-049]\n",
      " [1.00000000e+000 7.92038119e-106 0.00000000e+000]\n",
      " [2.50276013e-052 1.00000000e+000 1.65222470e-045]\n",
      " [8.34530715e-128 7.07560255e-040 1.00000000e+000]\n",
      " [4.34414019e-134 1.93915450e-076 1.00000000e+000]\n",
      " [6.25169892e-060 9.99999993e-001 6.94540909e-009]\n",
      " [3.71660604e-059 1.00000000e+000 4.71719329e-070]\n",
      " [8.93159223e-060 1.00000000e+000 5.48314479e-018]\n",
      " [1.00000000e+000 1.44477866e-081 0.00000000e+000]\n",
      " [1.00000000e+000 1.78779501e-061 0.00000000e+000]\n",
      " [2.47532839e-139 2.51569303e-056 1.00000000e+000]\n",
      " [1.00000000e+000 2.00081231e-042 1.88120290e-292]\n",
      " [5.84173391e-079 3.30033840e-018 1.00000000e+000]\n",
      " [1.00000000e+000 2.23002024e-069 0.00000000e+000]\n",
      " [1.00000000e+000 3.18788806e-080 0.00000000e+000]\n",
      " [1.13181501e-186 1.60769187e-097 1.00000000e+000]\n",
      " [3.52991593e-147 1.50414538e-072 1.00000000e+000]]\n"
     ]
    }
   ],
   "source": [
    "# Convert to indicators\n",
    "convert_to_indicators()\n",
    "\n",
    "# Set shape parameters\n",
    "Ntrain, D = Xtrain.shape\n",
    "Ntest = Xtest.shape[0]\n",
    "K = Titrain.shape[1]\n",
    "\n",
    "# initialize the weight matrix\n",
    "w = np.random.rand(D+1, K)\n",
    "\n",
    "# iterate to update weights\n",
    "niter = 1000\n",
    "alpha = 0.1\n",
    "\n",
    "# Add bias to data\n",
    "X1train = np.hstack((np.ones((Ntrain, 1)), Xtrain))\n",
    "\n",
    "likeli = []\n",
    "for step in range(niter):\n",
    "\n",
    "    ys = g(X1train, w)\n",
    "\n",
    "    w += alpha * X1train.T @ (Titrain - ys)\n",
    "    \n",
    "# Get class probabilities for each sample in X1train\n",
    "Ytrain = g(X1train, w)\n",
    "\n",
    "# Add bias to test data\n",
    "X1test = np.hstack((np.ones((Ntest,1)), Xtest))\n",
    "# Get class probabilities for each sample in X1test\n",
    "Ytest = g(X1test, w)\n",
    "\n",
    "print(Ytrain)\n",
    "print(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1, 0, 2, 0, 2, 2, 1, 1, 2, 0, 0, 2, 0, 2, 2, 0, 2, 1, 1, 1,\n",
       "       2, 0, 1, 2, 1, 1, 0, 2, 2, 2, 1, 1, 1, 1, 0, 2, 0, 1, 2, 2, 2, 2,\n",
       "       1, 0, 0, 0, 0, 1, 1, 2, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 1, 0, 0, 2,\n",
       "       1, 0, 2, 0, 0, 1, 2, 0, 1, 0, 0, 2, 2, 1, 2, 1, 2, 0, 2, 1, 2, 2,\n",
       "       2, 1, 0, 2, 0, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 0, 1, 2, 2, 1, 0, 2,\n",
       "       2, 1, 1, 0, 0, 2, 1, 2, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ltrain = np.argmax(Ytrain, axis=1) \n",
    "Ltrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 2, 1, 0, 0, 0, 2, 2, 1, 0, 1, 0, 1, 2, 2, 1, 1, 1, 0,\n",
       "       0, 2, 0, 2, 0, 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ltest = np.argmax(Ytest, axis=1) \n",
    "Ltest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training results')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Ttrain, 'ro')\n",
    "plt.plot(Ltrain, 'bx')\n",
    "plt.title(\"Training results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Test results')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Ttest, 'ro')\n",
    "plt.plot(Ltest, 'bx')\n",
    "plt.title(\"Test results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ltest==Ttest.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accuracy(y, t, name):\n",
    "    N = y.shape[0]\n",
    "    n_correct = np.sum(y.flat == t.flat)\n",
    "    n_correct_percent =  (n_correct / N) * 100\n",
    "    print(\"{} accyracy:\\t{}/{}\\t{} %\".format(name, n_correct, N, n_correct_percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accyracy:\t116/120\t96.66666666666667 %\n",
      "Test accyracy:\t30/30\t100.0 %\n"
     ]
    }
   ],
   "source": [
    "print_accuracy(Ltrain, Ttrain, \"Train\")\n",
    "print_accuracy(Ltest, Ttest, \"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(Y, T):\n",
    "    \"\"\"\n",
    "        Y    ndarray\n",
    "             predicted labels\n",
    "        T    ndarray\n",
    "             target labels\n",
    "             \n",
    "        @cfm DataFrame\n",
    "             confusion matrix\n",
    "    \"\"\"\n",
    "    if len(Y) != len(T):\n",
    "        raise ValueError(\"Wrong prediction and target length!\")\n",
    "    \n",
    "    classes = np.unique(T)\n",
    "    n_classes = len(classes)\n",
    "    \n",
    "    cfm = pd.DataFrame(np.zeros((n_classes, n_classes)), index=classes, columns=classes, dtype=int)\n",
    "    \n",
    "    Tidx = [T == c for c in classes]\n",
    "    for c in classes:\n",
    "        pred_idx = Y == c\n",
    "        cfm.loc[c, :] = [np.sum(np.logical_and(pred_idx, tidx)) for tidx in Tidx]\n",
    "    \n",
    "    return cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  1  2\n",
       "0  13  0  0\n",
       "1   0  8  0\n",
       "2   0  0  9"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfm = confusion_matrix(Ltest.flat, Ttest.flat)\n",
    "cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision, Recall, and F1-score \n",
    "Now that we have our confusion matrix we can use it to compute new metrics that inform us about different aspects of our models performance. Recall that we discussed precision, recall, and the F1-score in the class notes. Let's do a quick review of what these scores mean and how to compute them.\n",
    "\n",
    "### Precision\n",
    "Precision represents the accuracy when only looking at our **positive predictions**. Meaning, we want to know how many of our positive predictions were correct out of all the positive predictions made. Hence, we divide by the sum of the true positives $\\mathrm{TP}$ and false positives $\\mathrm{FP}$. Notice, the sum these two variables is equal the total number of positive predictions made for a given class.\n",
    "$$\n",
    "Precision = \\mathrm{\\frac{TP}{TP + FP}}\n",
    "$$\n",
    "\n",
    "### Recall\n",
    "Recall represents the accuracy when only looking at the **positive targets**. This means we want to know how many positive predictions we got correct out of the actual positive targets. Hence, we divide by the sum of true positives $\\mathrm{TP}$ and false negatives $\\mathrm{FN}$. Notice the sum these two variables is equal the total number of targets for a given class.\n",
    "$$\n",
    "Recall = \\mathrm{\\frac{TP}{TP + FN}}\n",
    "$$\n",
    "\n",
    "### F1-score\n",
    "The F1-score is used to gain a combined measure of both precision and recall. To do so we calculate the harmonic mean (the reciprocal of the arithmetic mean) of the precision and recall scores. F1-score is a good alternative to accuracy if the number false negatives and false positives are important to your problem. \n",
    "$$\n",
    "F_1 = 2 \\times \\frac{Precision \\times Recall}{Precision+Recall} = \\frac{2 \\times tp}{2 \\times tp + fp + fn}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setosa:\n",
      "\tPrecision (setosa): 1.00000\n",
      "\tRecall (setosa): 1.00000\n",
      "\tF1 Score (setosa): 1.00000\n",
      "versicolor:\n",
      "\tPrecision (versicolor): 1.00000\n",
      "\tRecall (versicolor): 1.00000\n",
      "\tF1 Score (versicolor): 1.00000\n",
      "virginica:\n",
      "\tPrecision (virginica): 1.00000\n",
      "\tRecall (virginica): 1.00000\n",
      "\tF1 Score (virginica): 1.00000\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    t_name = iris.target_names[i]\n",
    "    print(\"{}:\".format(t_name))\n",
    "\n",
    "    precision = cfm.iloc[i, i] / np.sum(cfm.iloc[i, :])\n",
    "\n",
    "    recall = cfm.iloc[i, i] / np.sum(cfm.iloc[:, i])\n",
    "\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    # Print scores for each class\n",
    "    print(\"\\tPrecision ({}): {:.5f}\".format(t_name, precision))\n",
    "    print(\"\\tRecall ({}): {:.5f}\".format(t_name, recall))\n",
    "    print(\"\\tF1 Score ({}): {:.5f}\".format(t_name, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
